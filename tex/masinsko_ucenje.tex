\chapter{Mašinsko učenje}

Mašinsko učenje počelo je da stiče veliku popularnost devedesetih godina prošlog veka zahvaljujući potrebi i mogućnosti da se uči iz ogromne količine dostupnih podataka i uspešnosti ovog pristupa u tome. Za popularizaciju mašinskog učenja početkom 21. veka najzaslužnije su neuronske mreže, u toj meri da je pojam mašinskog učenja često poistovećen sa pojmom neuronskih mreža. Ovo, naravno, nije tačno; sem neuronskih mreža, postoje razne druge tehnike, kao što su metod potpornih vektora, genetski algoritmi, itd. \par

Mašinsko učenje nastalo je iz čovekove želje da oponaša prirodne mehanizme učenja kod čoveka i životinja kao jedne od osnovnih svojstava inteligencije i korišćenja dobijenih rezultata u cilju praktične upotrebe. Termin mašinsko učenje prvi je upotrebio pionir veštačke inteligencije, Artur Semjuel\footnote{\url{https://en.wikipedia.org/wiki/Machine_learning} -- da li da citiram Wiki ili njihov izvor?}, koji je doprineo razvoju veštačke inteligencije istražujući igru dame (eng. checkers) i tražeći način da stvori računarski program koji na osnovu iskusva može da savlada ovu igru\footnote{\url{http://infolab.stanford.edu/pub/voy/museum/samuel.html} -- kako citirati izvor sa veba?}. \par

Mašinsko učenje može se definisati kao disciplina koja se bavi izgradnjom prilagodljivih računarskih sistema koji su sposobni da poboljšaju svoje performanse koristeći informacije iz iskustva \footnote{\url{http://poincare.matf.bg.ac.rs/~janicic/courses/vi.pdf} -- pretpostavljam da stavim referencu ka literaturi gde će knjiga biti navedena?}. No, u biti mašinskog učenja leži generalizacija, tj. indukcija. Dve vrste zaključivanja, indukcija\footnote{Indukcija -- zaključivanje od pojedinačnog ka opštem} i dedukcija\footnote{Dedukcija -- zaključivanje od opšteg ka konkretnom} imaju svoje odgovarajuće discipline u sklopu veštačke inteligencije: mašinsko učenje i automatsko rezonovanje. Kao što se indukcija i dedukcija razlikuju, i mašinsko učenje i automatsko rezonovanje imaju različite oblasti primene. Automatsko rezonovanje zasnovano je na matematičkoj logici i koristi se kada problem čovek relativno lako može formulisati ali ga, često zbog velikog prostora mogućih rešenja, ne može jednostavno rešiti. U ovoj oblasti, neophodno je dobiti apsolutno tačna rešenja, ne dopuštajući nikakav nivo greške.
Pri mašinskom učenju, teže je formalno definisati problem jer postoji relativno visok nivo apstrakcije. Čovek neke od ovih problema lako rešava a neke ne. Ukoliko je neophodno napraviti sistem koji prepoznaje lica na slikama, kako definisati problem? Od čega se tačno sastoji lice? Kako prepoznati elemente lica? Metodama automatskog rezonovanja bilo bi nemoguće definisati ovaj problem i rešiti ga. Mašinsko učenje, s druge strane, pokazalo se kao dobar pristup. Ono što je još karakteristično za mašinsko učenje jeste da rešenje ne mora biti savršeno tačno, iako se tome teži, i nivo prihvatljivog odstupanja zavisi od problema i konteksta primene. \par

Ova oblast je kroz manje od 20 godina od popularizacije postala deo svakodnevnice. U sklopu društvene mreže Fejsbuk (eng. Facebook) implementiran je sistem za prepoznavanje lica koji preporučuje profile osoba koje se nalaze na slikama. Razni veb servisi koriste metode mašinskog učenja radi stvaranja sistema za preporuke (artikala u prodavnicama, video sadržaja na platformama za njihovo gledanje, itd.) i sistema za detekciju prevara. Mnoge firme koje se bave trgovinom na berzi imaju sisteme koji automatski trguju deonicama. U medicini, jedna od primena mašinskog učenja jeste za uspostavljanje dijagnoze. Još neke primene su u marketingu, za procesiranje prirodnih jezika, bezbednost, itd.

%[ODNOS MASINSKOG UCENJA I OSTALIH OBLASTI MATEMATIKE?]

\section{Vrste mašinskog učenja}

Kada se priča o određenoj vrsti mašinskog učenja, podrazumevaju se vrste problema, kao i načini za njihovo rešavanje. Prema problemima koji se rešavaju, mašinsko učenje deli se na tri vrste: nadgledano učenje (eng. supervised learning), nenadgledano učenje (eng. unsupervised learning) i učenje potkrepljivanjem (eng. reinforcement learning). Iako se podela mnogih autora sastoji samo iz nadgledanog i nenadgledanog učenja, postoji razlika između učenja potkrepljivanjem i preostale dve vrste. U nastavku su dati opisi pristupa nadgledanog i nenadgledanog učenja. Učenju uslovljavanjem, kao centralnoj temi ovog rada, posvećeno je više pažnje u poglavlju~ \ref{ch:rl}. 

\subsection{Nadgledano mašinsko učenje}

Pri nadgledanom mašinskom učenju, date su vrednosti ulaza i izlaza koje im odgovaraju za određeni broj slučajeva. Sistem treba na osnovu već datih veza za pojedinačne parove da ustanovi kakva veza postoji između tih parova i izvrši generalizaciju, odnosno, ukoliko ulazne podatke označimo sa $x$ a izlazne sa $y$, sistem treba da odredi funkciju $f$ takvu da 
\begin{center}
	$y \approx f(x)$
\end{center}
Pri uspešno rešenom problemu nadgledanog učenja, funkcija $f$ davaće tačna rešenja i za podatke koji do sada nisu viđeni.
Ulazne vrednosti nazivaju se atributima (eng. features) a izlazne ciljnim promenljivima (eng. target values). Ovim opisom nije određema dimenzionalnost ni za ulazne ni za izlazne promenljive, iako je dimenzija izlazne promenljive uglavnom 1. Funkcija $f$ naziva se modelom. \par
Skup svih mogućih funkcija odgovarajuće dimenzionalnosti bio bi previše veliki za pretragu i zbog toga se uvode pretpostavke o samom modelu. Pretpostavlja da je definisan skup svih dopustivih modela i da je potrebno naći najpogodniji element tog skupa. Najčešće je taj skup određen parametrima, tj. uzima se da funkcija zavisi od nekog parametra $w$ koji je u opštem slušaju višedimenzioni i funkcija se označava kao $f_w(x)$.

\par
Neophodno je uvesti funkciju greške modela (eng. loss function), odnosno funkciju koja opisuje koliko dati model dobro određuje izlaz za dati ulaz. Ova funkcija se najčešće označava sa $L$ i $L(y, f_w(x))$ predstavlja razliku između željene i dobijene vrednosti za pojedinačni par promenljivih. No, nijedan par promenljivih nije dovoljan za opis kvaliteta modela već treba naći funkciju koja globalno ocenjuje odstupanje modela od stvarnih vrednosti. U praksi, podrazumeva se postojanje uzorka:
\begin{center}
	$D=\{(x_i, y_i)|i=1,...,N\}$
\end{center}
i uvodi se empirijski rizik, odnosno sledeća funkcija:
\begin{center}
	$E(w, D) = \frac{1}{N}\sum_{i=1}^{N}L(y_i, f_w(x_i))$
\end{center}
koja se još naziva prosečnom greškom. Takođe se skup $D$ često ne navodi i njegovo postojanje se podrazumeva. Uobičajeno, algoritmi nadgledanog mašinskog učenja zasnivaju se na minimizaciji prosečne greške. Ipak, treba imati u vidu da ovaj pristup nije teorijski zagarantovan i da to zavisi od skupa modela po kom se vrši minimizacija. \par

Postoje dva osnovna tipa nadgledanog mašinskog učenja:
\begin{itemize}
	\item Klasifikacija 
	\item Regresija
\end{itemize}

Klasifikacija (eng. classification) predstavlja oblast mašinskog učenja gde je cilj predvideti klasu u kojoj se ciljna promenljiva nalazi. Neki od primera klasifikacije su svrstavanje slika na one koje sadrže ili ne sadrže lice, označavanje nepoželjne (spam) elektronske pošte i prepoznavanje objekata na slikama. 
Najjednostavniji primer klasifikacije može se videti na slici \ref{fig:bin_klas}, gde su trouglovima označeni podaci iznad prave $y=2x+1$ a krugovima podaci ispod date prave.

\begin{figure}
	\centering
	\resizebox{.8\linewidth}{!}{\input{img/bin_cls.pgf}}
	\caption{Binarna klasifikacija tačaka u skladu sa položajem u odnosu na pravu $2x+1$}
	\label{fig:bin_klas}
\end{figure}

\par
Regresija se odnosi na skup problema (i rešenja) u kojima je ciljna promenljiva neprekidna. Na primer, cene nekretnina mogu se predvideti na osnovu površine, lokacije, populacije koja živi u komšiluku, itd. Često korišćena vrsta regresije jeste linearna regresija. U slučaju linearne regresije, podrazumeva se da je funkcija $f_w(x)$ linearna u odnosu na parametar $w$. Iako se ovo na prvi pogled čini kao prilično jako ograničenje, to nije slučaj; kako za atribute ne postoji zahtev za linearnosti, oni pre pravljenja linearne kombinacije mogu biti proizvoljno transformisani. Primer linearne regresije jeste aproksimacija polinomom:
\begin{center}
	$f_w(x) = w_0 + \sum_{i=1}^{N}w_ix^i$
\end{center}

\subsection{Nenadgledano mašinsko učenje}

Nenadgledano učenje obuhvata skup problema (i njihovih rešenja) u kojima sistem prihvata ulazne podatke bez izlaznih. Ovo znači da sistem sam mora da zaključi kakve zakonitosti važe u podacima.  Kako nije moguće odrediti preciznost sistema pa je cilj naći najbolji model u odnosu na neki kriterijum koji je unapred zadat.
Jedan primer nenadgledanog mašinskog učenja je klasterovanje: sistem grupiše neoznačene podatke u odnosu na  neki kriterijum koji nije unapred poznat. Svaka grupa (klaster) sastoji se iz podataka koji su međusobno slični i različiti od elemenata preostalih grupa u odnosu na taj kriterijum. Jednostavan primer klasterovanja po numeričkim atributima x i y može se videti na slici \ref{fig:klaster}.
	
\begin{figure}
	\centering
	\resizebox{.8\linewidth}{!}{\input{img/cluster.pgf}}
	\caption{Klasterovanje}
	\label{fig:klaster}
\end{figure}

\section{Dizajn sistema za mašinsko učenje}

Okvirno, koraci u rešavanju problema su sledeći:
\begin{itemize}
	\item Prepoznavanje problema mašinskog učenja (nadgledano učenje, nenadgledano učenje, učenje potkrepljivanjem);
	\item Prikupljanje i obrada podataka, zajedno sa odabirom atributa;
	\item Odabir skupa dopustivih modela;
	\item Odabir algoritma učenja; moguće je odabrati postojeći algoritam ili razviti neki novi koji bolje odgovara problemu
	\item Izbor mere kvaliteta učenja;
	\item Obuka, evaluacija i, ukoliko je neophodno, ponavljanje nekog od prethodnih koraka radi unapređenja naučenog modela 
\end{itemize}

Prilikom odabira modela treba imati na umu vrstu problema koja se rešava, količinu podataka, zakonitosti koje važe u podacima, itd.
Slika \ref{fig:odabir} prikazuje razliku između dva modela iz skupa dopustivih modela za linearnu regresiju polinomom nad 10 različitih tačaka. Na levom delu slike prikazan je polinom reda 1 (prava) a na desnom delu prikazan je polinom reda 10. Iako će polinom reda 10 savršeno opisivati 10 tačaka sa slike, vidi se da su one raspoređene blizu prave i, uprkos većem odstupanju modela od podataka za učenje, jasno je da je prava bolji izbor.

\begin{figure}
	\centering
	\resizebox{.45\linewidth}{!}{\input{img/prava_10.pgf}}
	\resizebox{.45\linewidth}{!}{\input{img/polinom_10.pgf}}
	\caption{Primer odabira modela pri linearnoj regresiji polinomom}
	\label{fig:odabir}
\end{figure}

\subsection{Podaci}

Mašinsko učenje bavi se generalizacijom nad nepoznatim objektima na osnovu već viđenih objekata. Pod pojmom objekta misli se na pojedinačni podatak koji sistem vidi. Koriste se još i izrazi primerak i instanca. Vrednosti podataka pripadaju nekom unapred zadatom skupu. Podaci mogu biti različitog tipa: numerički ili kategorički. Skupovi koji određuju vrednosti kojima se instance određuju nisu unapred zadati i neophodno ih je odrediti na način pogodan za rešavanje konkretnog problema. Na primer, ukoliko je neophodno razvrstati slike životinja i biljaka na te dve kategorije, informacija o količini zelene boje na slici može biti prilično korisna, dok pri razvrstavanju vrste biljaka u zavisnosti od lista ovaj podatak skoro nije upotrebljiv (ali podatak o nijansi zelene boje može biti). Dakle, dobar izbor atributa imaće veliki uticaj na kasnije korake učenja. Podaci se sistemu daju kao vektori atributa. \par

Podaci se neretko pre slanja sistemu obrađuju na neki način; ovaj postupak zove se pretprocesiranje. Postoje mnogi razlozi za pretprocesiranje a glavni cilj jeste da dobijemo objekte nad kojima učenje može da se desi. Međutim, i to zavisi od problema. Nekada će nepotpuni objekti, podaci koji ne sadrže sve informacije neophodne za učenje, biti izbačeni iz skupa podataka koji se razmatra, a u nekom drugom slučaju, i oni će biti korišćeni. Jedan primer pretprocesiranja jeste pretvaranje slike koja je u boji u crno beli zapis.

\subsection{Evaluacija modela}

Nakon obučavanja (treniranja), neophodno je izvršiti evaluaciju dobijenog modela. Na koji god način se ovo izvršava, podaci korišćeni za obučavanje ne smeju se koristiti za evaluaciju modela. Često se pribegava podeli podataka na skupove za obučavanje i za testiranje. Skup za obučavanje obično iznosi dve trećine skupa ukupnih podataka. No, kako različite podele skupa mogu izazvati dobijanje različitih modela, slučajno deljenje nije najbolji izbor.  Često korišćena tehnika jeste unakrsna validacija. Ovaj pristup podrazumeva podelu skupa podataka $D$ na $K$ podskupova približno jednake veličine, $S_i$ za $i=1,...,K$. Tada se za svako $i$ model trenira na skupu $D \setminus S_i$ a evaluacija se vrši pomoću podataka iz $S_i$. Posle izvedenog postupka za sve $i$, kao konačna ocena uzima se prosečna ocena svakog od $K$ treniranja i evaluacija modela. Za vrednosti $K$ uobičajeno se uzimaju vrednosti 5 ili 10. Ovaj metod vodi pouzdanijoj oceni kvaliteta modela.

\section{Problemi pri mašinskom učenju}


Kao što je podrazumevano pri pomenu pojma generalizacije, nije dovoljno odrediti funkciju koja dobro određuje izlazne vrednosti na osnovu promenljivih nad kojima se uči već je poželjno i novim ulaznim podacima dodeliti tačnu izlaznu vrednost. Odavde se može videti da će loš sistem za mašinsko učenje izuzetno dobro naučiti da preslikava ulazne vrednosti iz skupa za učenje u odgovarajuće izlazne vrednosti ali u situaciji kada se iz tog skupa izađe sistem neće davati zadovoljavajuće rezultate. Ovaj problem ima svoje ime: preprilagođavanje. Postoji i problem potprilagođavanja, koji podrazumeva da se sistem nije dovoljno prilagodio podacima. I preprilagođavanje i potprilagođavanje predstavljaju veliki problem ukoliko do njih dođe. Primer preprilagođavanja može se videti na slici \ref{fig:odabir}. Polinomom stepena 10 model se savršeno prilagodio podacima za trening ali neće biti u stanju da izvrši generalizaciju za nove podatke. \par
Na još jedan od mogućih problema nailazi se u slučaju neprikladnih podataka. Moguće je da ulazni atributi ne daju dovoljno informacija o izlaznim. Takođe je moguće da podataka jednostavno nema dovoljno. U ovom slučaju, sistem ne dobija dovoljno bogat skup informacija kako bi uspešno izvršio generalizaciju. S druge strane, moguće je da postoji prevelika količina podataka. Tada se pribegava pažljivom odabiru podataka koji se koriste za učenje ali ovo u opštem slučaju  treba izbegavati jer su podaci izuzetno vredan element procesa mašinskog učenja. Još jedan problem vezan za podatke može biti njihova nepotpunost. Na primer, moguće je da u nekim instancama postoje nedostajuće vrednosti atributa. \par
Kako je najčešče potrebno pretprocesirati podatke u sklopu procesa mašinskog učenja, moguće je da u ovom postupku dođe do greške. Primera radi, prilikom rada sa konvolutivnim neuronskim mrežama, o kojima će biti reči u jednom od narednih glava, nekada se slike  u boji pretvaraju u crno-bele. Ako se primeni transformacija koja onemogućuje razlikovanje objekata koji su različiti u početnoj slici a razlikovanje je neophodno za ispravno učenje sistema, tada proces treniranja neće teći kako je planirano. \par


% [ONO ZA RGB U GRAY U DQN BI BILO SOLIDNO OVDE UBACITI] \par
Problem može da nastane i ukoliko nije odabran pravi algoritam za učenje, ukoliko se loše pristupilo procesu optimizacije, prilikom lošeg procesa evaluacije i, naravno, prilikom loše implementacije algoritma. Sve ove prepreke moguće je prevazići ali je jasno da je neophodno biti izuzetno pažljiv prilikom celog procesa mašinskog učenja.